call_super_init: false
contrastive_temperature: 1.0
dataset: dataset_storage/baby-lm-small.hf
emb_loss_weight: 1.0
emb_predictor: Identity
hidden_dim: 768
learning_rate: 0.0001
loss_name: cwt
mask_prob: 0.15
mask_token_id: 1
max_seq_len: 128
mlm_loss_weight: 0.0
mlm_model: bert-base-cased
num_tokens: 30522
pad_token_id: 0
random_token_prob: 0.1
replace_prob: 0.8
task: MlmHeadlessPretraining
text_key: packed
tokenized: true
total_nb_steps: 1000000.0
train_batch_size: 16
val_batch_size: 16
warmup_steps: 10000.0
weight_decay: 0.01
